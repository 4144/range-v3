<table border="0" cellpadding="0" cellspacing="0" style="border-collapse: collapse" bordercolor="#111111" width="607">
    <tr>
        <td width="172" align="left" valign="top">Document number:</td>
        <td width="435"><span style="background-color: #FFFF00">D4128</span>=yy-nnnn</td>
    </tr>
    <tr>
        <td width="172" align="left" valign="top">Date:</td>
        <td width="435">2014-07-26</td>
    </tr>
    <tr>
        <td width="172" align="left" valign="top">Project:</td>
        <td width="435">Programming Language C++, Library Working Group</td>
    </tr>
    <tr>
        <td width="172" align="left" valign="top">Reply-to:</td>
        <td width="435">Eric Niebler &lt;<a href="mailto:eniebler@boost.org">eniebler@boost.org</a>&gt;</td>
    </tr>
</table>

Ranges for the Standard Library, Revision 1
===========================================

I. Table of Contents
--------------------

TODO

II. Introduction
----------------

This paper outlines what support for ranges in the C++ standard library might look like. Rather than presenting a final design, this paper proposes a set of concepts and guidelines for using them to implement range-based versions of the standard algorithms. It draws inspiration from the Boost.Range library, the range algorithms in Adobe Source Libraries, *Elements of Programming* by Stepanov and McJones (2009), and from N3351 "A Concept Design for the STL" by Stroustrup and Sutton (2012). In addition to presenting the concepts and guidelines, this paper discusses the rationale behind each, weighing different design options. The paper is intended as a starting point for discussion and as a basis for future work.

This paper assumes the availability of Concepts Lite; however, everything suggested here has been implemented in C++11, where Concepts Lite has been simulated with the help of generalized SFINAE for expressions.

III. Motivation and Scope
-------------------------

A "range" is an object that refers to a sequence of elements, conceptually similiar to a pair of iterators. One prime motivation for ranges is to give users a simpler syntax for calling algorithms. Rather than this:

    std::vector<int> v { /*...*/ };
    std::sort( v.begin(), v.end() );

Ranges would give us a pithier syntax:

    std::sort( v );

Allowing algorithms to take a single range object instead of separate begin and end iterators brings other benefits besides convenience. In particular:

  * It eliminates the possiblility of mismatched iterators.
  * It also opens the door to *range adaptors* which lazily transform or filter their underlying sequence in interesting ways.

Range adaptors are far more compelling than iterator adaptors due to the fact that only a single object, the range object, needs to be adapted; hence, adaptors can be easily chained to create lazy computational pipelines, as in the code below which sums the first 10 squares:

    int total = accumulate(view::iota(1) |
                           view::transform([](int x){return x*x;}) |
                           view::take(10), 0);

The current standard does not define the term "range", but it is used in several places where it generally refers to two iterators of the same type, the second being reachable from the first. These two iterators denote a half-open range of elements.

Here are the ways one might want to specify a range:

* Two iterators
* An iterator and a count of elements
* An iterator and a (possibly stateful) predicate that indicates when the range is exhausted.

There are other interesting range types (e.g. an iterator and a sentinel value, like a null-terminated string) but these can be shown to generalize to one of the range types above.

### Range Design Goals

We feel that a well-designed range abstraction would:

* Allow algorithms to operate on the three kinds of ranges with low or no abstraction penalty and a minimum of syntactic noise,
* Allow range-based algorithms to share implementation with iterator-based algorithms,
* Make it easy for users to reason about the complexity and expense of range operations (e.g. How many passes over the data are made? Are the elements copied? etc.),
* Protect the user from lifetime issues,
* Make it straightforward for users to make their types model one of the range concepts.

It is helpful at this point to reflect on the success of C++11's range-based `for` loop. It succeeded because most of the types over which one would want to iterate already defined iterators and `begin`/`end` members. Cleanly and efficiently interoperating with and reusing the existing abstractions of the STL are critical to the success of any range extensions.

### High-Level Design

At the highest level, this paper proposes the addition of two related range concepts: Iterable and Range. Iterable is anything on which we can call `begin` and `end` to yield an iterator/sentinel pair. (Sentinels are discussed later.) The Iterable concept says nothing about the type's constructability or assignability. Range-based standard algorithms are constrained using the Iterable concept. Consider:

    int buf[5000];
    // Fill buf
    std::sort( buf );

`buf` denotes a range of elements, so we should be able to sort it, but native arrays are neither copyable nor assignable, so whatever range-like concept is used to constrain `sort`, it cannot require those.

The Range concept, on the other hand, is modeled by lightweight objects that denote a range of elements they don't own. A pair of iterators can easily model Range, whereas a `vector` cannot. Range, as opposed to Iterable, requires copyability and assignability. The algorithmic complexity of copy and assign is required to be O(1), as in: it does not depend on the number of elements in the Range.

The Range concept refines Iterable.

The Range concept exists to give the range adaptors consistent and predictable semantics, and memory and performance characteristics. Since adaptor chains aggregate range objects, the objects must be copyable (or movable at the very least). To be consistent and predictible, Ranges (which are lightweight) are required. Any attempt to adapt an Iterable that is not a Range is first made one by taking the Iterable's begin and end.

### Design Decisions, Guidelines, and Rationale

The design space for ranges is surprisingly large. At one end of the spectrum lies [Boost.Range] [2] and [Adobe's ASL] [3] in which ranges are a thin abstraction on top of iterators, which remain the primitives that glue together data structures and algorithms. At the other end of the spectrum we find the [D Standard Library's std.range module] [4], in which ranges and operations on them are the primitives themselves.

This proposal picks a single point in this design space, and here we present the decisions that led to the selection of that point, along with guidelines to be applied to the standard library and the rationale for each choice.

#### Iterator Operations are Primitive

To date, the most comprehensive effort to replace iterators with ranges as low-level primitives was undertaken by Andrei Alexandrescu when designing the D Standard Library. The result is, in the opinion of this author, a qualified success. See Appendix 3 for why I say "qualified".

This paper does not deeply explore the ranges-as-primitives approach taken by the D Standard Library. Such an approach would abandon a large investment in the iterator abstraction and create a schism within the standard library and in the community at large between range-based and iterator-based algorithms, which couldn't share code. We, the authors, consider such a schism unacceptable.

Although the concept of "sequence" undoubtably comes up more frequently in most domains than the "position in sequence" abstraction that iterators represent, completely banishing the concept of position leads to some awkward constructions. For example, trying to express an algorithm like `find` without the notion of "position" leads to the slightly contrived convention of returning a range. But which range to return? Indeed, the D Standard Library has as many `find` algorithms as there are answers to this question. (TODO reference)

Also, any algorithm that takes a range and a position within the range on which to do some operation (like `rotate`) becomes awkward and unwieldy without some notion of position.

Finally, iterators as primitives are provably more powerful than ranges. Any design that can be expressed with ranges can be expressed with iterators, but the converse is not true.

##### Position-Based Ranges

An alternate design is found in [James Touton's range library] [5], where ranges -- together with a new Position concept -- are the primitives. A Position, as its name suggests, represents a position in a range. Unlike an iterator, a position cannot be used to access the element at that position without the range into which it refers, nor can the position be advanced without the range.

This design has the following advantages:

* In making position a representable entity, it avoids the awkward constructions of D's range library.
* In requiring the range in order to dereference the position, it avoids all dangling iterator issues.
* In requiring the range in order to change the position, it makes range-checking trivial. This is a boon not just for debugability, but also for the design of certain range adaptors like filter and stride whose iterators need to know the end of the range so as not to walk past it.
* It permits a clean separation of element traversal and access, much like the suggested [cursor/property map abstraction] [11].

However, the design does not permit clean and efficient interoperation with the existing iterator abstraction. Bundling a range and a position into an iterator results in bloated iterators. All algorithms would need two implementations: one for ranges and one for iterators. For this reason, the position-based range design doesn't seem to meet our design goals.

#### Ranges Cannot Own Elements

As described above, a container is not a Range. It is, however, an Iterable. Distinguishing between the two makes it possible to be explicit about where copyability is required, and with what performance characteristics. Any Iterable that is not a Range is trivially convertible to a Range by simply taking its begin and end.

The distinction between Iterables and Ranges becomes critical when defining adaptor chains. On what data is the chain operating? Who owns it? How many times is it copied? What does code like the following mean?

    auto rng = v | view::reverse;

Is `rng` copyable, and if so, how expensive is the copy operation? If `v` is a `vector`, can `rng` safely outlive `v`? How about if `v` is just a pair of iterators? What happens when a user does `*rng.begin() = 42`? Is `v` mutated? How do the answers change if we replaced `v` with an rvalue expression? If a copy of `rng` is made, and an element is mutated through the copy, does the original `rng` object also change? A well-designed range abstraction must answer these thorny questions.

By requiring that Ranges do *not* own their elements, and further requiring that range adaptors operate on and produce Ranges, we are able to answer these questions in a clear and consistent way. The result of a chain of range adaptors is always a lightweight object that is cheap to copy and assign (O(1) as opposed to O(N)), and that refers to elements whose lifetime is managed by some other object. Mutations of elements through the resulting Range object mutates the underlying sequence. Copies of the resulting range are aliases to the same elements, and mutations to the elements effect all the aliased ranges.

The downside of this design is that it is sometimes desirable to do this:

    // Try to adapt an rvalue container
    auto rng = vector<int>{1,2,3,4} | view::reverse; // OK?

As mentioned, the adaptors operate on and yield Ranges; other Iterables are made Ranges by first taking their begin and end. That is obviously unsafe in the code above since `rng` will be left holding invalid iterators into a container that no longer exists. Our solution is to disallow the above code. *It is illegal to adapt an rvalue non-Range.* (Adapting rvalue Ranges, however, is perfectly acceptable; indeed necessary if adaptor pipelines are to be supported.)

The alternative is for the rvalue container to be moved (or copied) into the adapted range and held by value. The resulting object would therefore no longer model Range; it would model Iterable. The authors feel that this weakening of the requirements on the return type makes it difficult to reason about the semantics and algorithmic complexity of range adaptors. The alternative is to first declare the container and create the adaptor separately.

#### Neither Ranges Nor Iterables Are EqualityComparable

Two vectors compare equal iff they have the same size and each element compares equal. Are Ranges also equality comparable, and with what semantics?

We've already decided that Ranges (not Iterables) are copyable and assignable. They are, in the terminology of EoP and N3351, Semiregular types. What's more, we have said that since Ranges are a kind of proxy, they are cheap to copy and assign. To make them EqualityComparable is to make them Regular types. EoP has much to say about Regular types and the relationship between copy, assign, and equality comparison. If the first two operations are creating aliases and O(1), it would be very strange for the third to do anything besides testing whether two ranges are aliases, and *very* strange for it to be O(N).

As a result, it seems undesirable to define a general Range-based `operator==` that tests whether all the elements in the range are equal. That would make Range model the syntactic requirements of Regular without satisfying its axioms. The inconsistency in the algorithmic complexities of the three fundamental operations is simply too confusing.

The question then is whether Range should require EqualityComparable with the appropriate semantics; that is, to test whether two Ranges refer to the *same* elements. Although such a requirement is appealing in theory, it has problems:

* It might conflict with users' expectations of what `rng1 == rng2` means.
* It is impossible to implement with those semantics in O(1) for some range types; for example, a filter range that stores a predicate. Functions are generally not EqualityComparable.

Another option is to allow Ranges to trivially model EqualityComparable by narrowly defining the domain over which the operation is valid. Iterators may only be compared if they refer into the same range. We can extend the reasoning to Ranges, which are logically little more than pairs of iterators. Taking this tack, we could allow a Range type to define its `operator==` as:

    rng1.begin() == rng2.begin() && rng1.end() == rng2.end()

The assumption being that the operation is invalid if `rng1` and `rng2` refer to different elements. Although principled (for some set of principles), such a definition is almost certain to lead users into undefined behavior-land.

As a result of the above, we have decided that the Range concept should not require EqualityComparable. Ranges are Semiregular, not Regular.

If a user would like to check to see if two ranges have elements that compare equal, we suggest the `equal` algorithm:

    if(std::equal(rng1, rng2))
        // ...

TODO : Re-express the below, integrate the guidelines discussion.

#### Can Iterators Outlive Their Ranges?

Containers own their elements, so it is clear that the container must outlive the iterators it generates. It's not clear that the same must be true for ranges. After all, a range does not own its elements. In the simplest case, where a range is simple a pair of iterators, it's clear that the iterators may in fact outlive the range object. But is that always a safe bet?

It turns out that if we require that a range's iterators be permitted to outlive the range, a great many interesting range types become significantly more expensive at runtime. A good case study is the filter view.

A filter view takes a range and a predicate, and presents a view of the sequence that skips the elements for which the predicate is false. (The filter view can be thought of a lazy equivalent of the `copy_if` algorithm.) The existence of the `boost::filter_iterator` shows that such an iterator *can* be made such that it doesn't depend on a range, but at a cost. The `filter_iterator` stores:

 1. An iterator that indicates the current position in the underlying sequence.
 2. An iterator that indicates the end of the underlying sequence (needed by the increment operators to avoid falling off the end while searching for an element that satisfies the predicate).
 3. The predicate.

In today's STL, the begin and end iterators must have the same type, and they are both needed to call an algorithm. Thus, the information in (2) and (3) is duplicated. Also, the predicate may be expensive the copy, given the ease with which capture-by-value lambdas and `std::function`s can be created. When such iterators are composed with other kinds of views (e.g., a transformed, filtered view), the bloat compounds exponentially. (See [Indexed-Based Ranges] [10].)

By relaxing the constraint that a range's begin and end must have the same type, we can avoid the duplication, but the begin iterator still must hold everything, which is potentially expensive.

If, however, we could rely on the range object outliving the iterator, we can make the filter iterators smaller and lighter. The range object can hold the predicate and the underlying range's begin/end iterators. The filter view's iterator only needs to hold the current position and a pointer back to the range object.

#### Can End Iterators Have a Different Type Than Begin Iterators?

TODO

#### Is the Orthogonality of Traversal and Access Surfaced in the Iterator Concepts?

The current iterator concept heirarchy ties together the traversal and access properties of iterators. For instance, no forward iterator may return an rvalue proxy when it is dereferenced; the ForwardIterator concept requires that unary `operator*` return an lvalue. And only random-access iterators can jump forward. There is no room in the heirarchy for, say, a random-access iterator that returns proxies.

This problem is not new to ranges; however, it has serious consequnces for lazy ranges that apply transformations to elements on the fly. If the transformation function does not return an lvalue, the range's iterator can model no concept stronger than InputIterator, even if the resulting iterator could in theory allow random access. The result in practice is that most range adaptors have the unfortunate effect of degrading the underlying range's category to Input, thereby limiting the number of algorithms it can be passed to -- often for no good reason.

Prior work as been done by [Abrahams et. al.] [9] to separate the traversal and access properties of iterators in a way that is backwards compatible. When formalizing the iterator concepts for a range library, should the new iterator concepts be used, or should we hew to the old, simpler concept heirarchy with its known limitations?

IV. Impact on the Standard
--------------------------

This paper imagines changes to the following parts of the standard:

- New library-wide concepts related to ranges.
- New iterator algorithms for efficiently dealing with the new abstractions.
- Changes existing algorithms to constrain the templates
- Additional overloads of existing algorithms that accept ranges instead of pairs of iterators.
- Changes to the containers to allow containers to be constructed and assigned from ranges, and to allow range-based insert operations.
- A new library section for range adaptors, which are views of existing data that have been transformed or filtered and that compose with other views.
- General utilities for the construction of custom range adaptors.(???)
- A minor change to the specification of the range-based `for` to make it more efficient and general.

V. Design Decisions
-------------------

### Design Assumptions

The author has to make several assumptions when arriving at his design decisions, many of which may prove to be faulty or unjustifiable. They are:

- That concepts will be baked into some version of the standard library.
- That in that process, to avoid a repeat of the C++0x Concepts experience and to preserve strict backwards compatibility while delivering a *sane* set of concepts with which the standard library is constrained, it will be decided to deliver the new standard library along side the (unconstrained) old one, in a separate versioned namespace.
- That this opportunity will occasion the correction of small oversights in the library.

In other words, the author has given himself the freedom to make changes to the standard library that are not strictly source-code compatible with old code; that the integration of concepts will cause breakage *anyway*, so we might as well seize the opportunity to "do it right". If that turns out not to be the case, fallbacks will be discussed. (Most of the small breaking changes implied by the following design decisions have natural, conservative fallbacks. Those fallbacks are less satisfactory in that they either leave long-standing issues unaddressed or introduce new inconsistencies, but it's nothing we couldn't live with.)

### Summary of Design Decisions

*TODO Explain the whys behind these choices.*

The following is true of Ranges:

- The type of the end iterator (hereafter refered to as a "sentinel") can differ from that of the begin iterator.
- When a Range is destroyed, any iterators generated from that range are invalidated.
- Ranges do not logically own their elements. They refer to elements stored elsewhere (or are generated on demand).
- Ranges are Regular types, so copies are independent. An iterator from a Range `A` that was copied from `B`
  is not invalidated when `B` is destroyed.
- If an un-cv-qualified type `T` models Range, then the type `T const` need not. This permits ranges that maintain
  mutable internal state; e.g., an `istream` range.

The following is true of algorithms:

- Algorithms are changed to reflect the fact that the sentinel may have a different type than the begin iterator.
- Algorithms, in addition to the old versions that take begin/end iterator/sentinel arguments, now have versions
  that take Iterable arguments in place of begin/end pairs.
- Algorithm versions that take Iterables are semantically identical to the identically-named versions that takes
  iterator/sentinel pairs. The two flavors have the same return types. Both evaluate eagerly.
- Algorithms that necessarily process their entire input sequence return the iterator position at the end in
  addition to whatever else they return. The purpose is to return potentially useful information that is computed
  as a side-effect of the normal execution of the algorithm; for example, the position of a C-style string's null
  terminator. Exceptions to this design guideline are made when one of the following is true:
    * The algorithm might in some cases not consume the entire input sequence. (The point of this exception is
      to avoid forcing the algorithm to compute something that is not necessary for successful completion. For
      example, `find`.)
    * When the sole purpose of the algorithm is specifically to compute a single value; hence, changing
      the return type will necessarily break code using the C++11 version. Examples include `is_sorted` and
      `accumulate`.
- "Three-legged" iterator-based algorithms now have 4 versions:
    * The old three-legged iterator version (that has traditionally merely assumed the sequence denoted by the third
      iterator is long enough),
    * A four-legged version that uses the sentinel of the second sequence as an additional termination condition,
    * A version that takes an Iterable and an Iterator (which dispatches to the three-legged iterator-based version),
      and
    * A version that takes two Iterables (which dispatches to the four-legged iterator-based version).
- Purely as an implementation consideration, the three-legged algorithms must be able to distinguish a native array
  from an iterator; e.g. when the user calls the algorithm with an array as the second input sequence (where either
  an Iterable or an iterator is allowed to appear). Naively coded, this would be ambiguous due to the decay of arrays
  to pointers. In this case, it should dispatch to the version that takes two Iterables, not the version that takes
  an Iterable and an iterator.
- Algorithms that do not mutate their input sequence must also work when `initializer_list`s are used in place of
  Iterables.
- If an algorithm returns an iterator into an Iterable argument, the Iterable must be an lvalue. This is to avoid
  returning an iterator that is immediately made invalid. Conversely, if no iterator into an Iterable argument is
  returned, then the Iterable should be taken by "universal reference".
- Algorithms that take callables should work with any kind of INVOKE-able entity (see [func.require]); for example,
  pointers to data members are valid unary INVOKE-able objects.
- Wherever appropriate, algorithms should optionally take INVOKE-able *projections* that are applied to each element
  in the input sequence(s). This, in effect, allows users to trivially transform each input sequence for the sake
  of that single algorithm invocation. The reason for projections is described in
  [Sean Parent's "C++ Seasoning" talk] [6] on slide 38.
- Algorithms that take two input sequences should (optionally) take two projections.
- For algorithms that optionally accept functions/predicates (e.g. `transform`, `sort`), projection arguments
  positionally follow functions/predicates. There are no algorithm overloads that allow the user to specify the
  projection without also specifying a predicate, even if the default would suffice. This is to reduce the
  number of overloads and also to avoid any potential for ambiguity.

#### On Sentinels versus End Iterators

Arguably the most radical idea in this proposal is to allow the type of the end iterator to differ from the type of the begin iterator. Loosening the constraints of the end iterator brings several benefits:

* More sequence types can trivially qualify as "ranges" if the position of the end is not required to be known *a priori*; for example, a null-terminated character sequence, or a sequence whose end is determined by a predicate, or range specified by an iterator and a count.
* It eliminates the need to mock-up dummy end iterators, like `std::istream_iterator` and `std::regex_iterator`, the logic of which is tricky to get right.
* It improves code generation for some types of ranges. With the use of dummy end iterators, information which is known at compile-time -- namely, that an iterator represents the end -- must be encoded into runtime information in the iterator itself. When the type of the end iterator is allowed to differ, its "end-ness" can be encoded in the type system, which gives the compiler the information it needs to eliminate branches from the core loops of many algorithms. See Appendix 1 for an example of how sentinels can positively effect code generation.

When considering this choice for the range concept, it's helpful to think about how it would effect the algorithms. Consider `std::for_each`, which currently has this signature:

    template<class InputIterator, class Function>
    Function for_each(InputIterator first, InputIterator last, Function f)
    {
        for(; first != last; ++first)
            f(*first);
        return f;
    }

With sentinels, `for_each` might look like this:

    template<class InputIterator, class Sentinel, class Function>
        requires( /* ... constraints ... */ )
    Function for_each(InputIterator first, Sentinel last, Function f)
    {
        for(; first != last; ++first)
            f(*first);
        return f;
    }

None of the code in the algorithm had to change. No calling code would have to change either; this is a strictly backwards-compatible change. You might think that this opens a new category of programming errors where developers inadvertantly pass mismatched iterator/sentinel pairs. However, this algorithm signature would be constrained with concept checks that would ensure that `InputIterator` and `Sentinel` satisfied the cross-type EqualityComparable concept (see [N3351] [8]). See Appendix 2 for further discussion about Iterator/Sentinel cross-type EqualityComparability constraint.

To see the benefit of this design, imagine a sentinel type `null_sentinel`:

    // For determining whether an iterator refers to a null value:
    struct null_sentinel
    {
        template<Iterator I>
        friend bool operator==(I i, null_sentinel) { return 0 == *i; }
        template<Iterator I>
        friend bool operator==(null_sentinel, I i) { return 0 == *i; }
        template<Iterator I>
        friend bool operator!=(I i, null_sentinel) { return 0 != *i; }
        template<Iterator I>
        friend bool operator!=(null_sentinel, I i) { return 0 != *i; }
    };

Now we can use `std::for_each` on null-terminated strings without needing to know the length of the string:

    std::for_each(argv[1], null_sentinel(), f);

Of course, all the algorithms would have overloads that also accept range arguments, so this can be further simplified to:

    std::for_each(null_terminated(argv[1]), f);

where `null_terminated(InputIterator)` returns a range `r` such that the `std::end(r)` is a `null_sentinel`.

**Further Benefits of Sentinels**

One excuse sometimes given for not using the standard algorithm is that they don't give the users a way to break out of them early. The use of sentinels makes that possible. Consider a sentinel constructed from both an end iterator and a predicate. Such a sentinel would compare equal to an iterator *either* when the iterator equals the end iterator *or* when the predicate evaluates to true. Using such a sentinel has the effect of terminating an algorithm early. For instance:

    // Process work items in a queue, allowing for a user interrupt
    std::queue<Work> q;
    std::function<void(Work const &)> user_interrupt = /*...*/;
    std::for_each( q | until(user_interrupt), f );

In the above, `until` is a range modifier that adds an extra termination constraint, and `|` is the operation for generating range views by applying a modifier to a range.

**Further Implications of Sentinels**

Notice that in the due course of evaluating `std::for_each` with `null_sentinel`, the position of the null terminator is found. This is potentially useful information that can easily be returned to the user. It is, in fact, a far more interesting and useful result that the `Function` that `for_each` currently returns. So a better signature for `for_each` should look like this:

    // Returns an InputIterator i such that (i == last) is true:
    template<class InputIterator, class Sentinel, class Function>
        requires( /* ... constraints ... */ )
    InputIterator for_each(InputIterator first, Sentinel last, Function f);

In similar fashion, most algorithm get new return types when they are generalized to support sentinels. This is a source-breaking change in many cases. In some cases, like `for_each`, the change is unlikely to be very disruptive. In other cases it may be more so. Simply accepting the breakage is one possibility, and the one that leads to the cleanest design, and the fewest gotchas in the future.

A fallback design is to only change the return type when the types of the iterator and the sentinel differ. This leads to a slightly more complicated interface that may confuse users. It also greatly complicates generic code, which would need metaprogramming logic just to use the result of calling some algorithms. For this reason, this possibilty is not explored here.

The committee may decide to deliver the new standard library in a separate namespace that users must opt into. In that case, no code is broken until the user explicitly ports their code. The user would have to accomodate the changed return types then. An automated upgrade tool similiar to clang modernize (TODO REF) can greatly help here.

#### On Projections

The Adobe Source Libraries (ASL) pioneered the use of "projections" to make the algorithms more powerful and expressive by increasing interface symmetry. Sean Parent gives a motivating example in his ["C++ Seasoning" talk] [6], on slide 38. With today's STL, when using `sort` and `lower_bound` together with user-defined predicates, the predicate must sometimes differ. Consider:

    std::sort(a, [](const employee& x, const employee& y)
                 { return x.last < y.last; });
    auto p = std::lower_bound(a, "Parent", [](const employee& x, const string& y)
                                           { return x.last < y; });

Notice the different predicates used in the invocations of `sort` and `lower_bound`. Since the predicates are different, there is a chance they might get out of sync leading to subtle bugs.

By introducing the use of projections, this code is simplified to:

    std::sort(a, std::less<>(), &employee::last);
    auto p = std::lower_bound(a, "Parent", std::less<>(), &employee::last);

Every element in the input sequence is first passed through the projection `&employee::last`. As a result, the simple comparison predicate `std::less<>` can be used in both places.

No effort was made in ASL to use projections consistently. This proposal bakes them in everywhere it makes sense.

##### Projections versus Range Transform View

In a sense, the use of a projection parameter to an algorithm is similar to applying a transform view directly to a range. For example, calling `std::find` with a projection is similar to applying a transform to a range and calling without the projection:

    auto it = std::find( a, 42, &employee::age );

    auto a2 = a | view::transform( &employee::age );
    auto it2 = std::find( a2, 42 );

Aside from the extra verbosity of the view-based solution, there are two meaningful differences: (1) The type of the resulting iterator is different; `*it` refers to an `employee` whereas `*it2` refers to an `int`. And (2) if the transform function returns an rvalue, then the transformed view cannot model a forward sequence due to the requirements on the ForwardIterator concept. The result of applying a transform view is an Input range unless the transform function returns an lvalue. The projection-based interface suffers no such degredation of the iterator category. For those reasons, range transform adapters are not a replacement for projection arguments to algorithms.

##### Algorithm Implementation with Projections

Rather than requiring additional overloads, the additions of projection arguments has very little cost to library implementers. The use of function template default parameters obviates the need for overloads. For instance, `find` can be defined as:

    template<InputIterator I, typename S, typename V, UnaryFunction Proj = identity>
        requires( /* requirements */ )
    I find(I first, S last, V const & val, Proj proj = Proj{})
    {
        /* ... */
    }

### Range Concepts

The following concepts are proposed to constrain the standard library. The iterator concepts mentioned here are identical to those specified in N3351 except where specified.

##### Iterator Concepts

The range concepts presented below build on the following iterator concepts. These are largely as found in N3351, with the addition of WeakIterator, Iterator, WeakOutputIterator and OutputIterator. The entire heirarchy is presented here for completeness.

    concept WeakIterator<WeaklyIncrementable I> =
        Copyable<I> &&
        requires(I i) {
            not_void(*i);
        };

A WeakIterator is a WeaklyIncrementable type that is both copyable and dereferencable. We add the additional constraint that the result of the dereference operator is not void. This is refined below by the addition of either Readable or Writable. Iterator and WeakIterator are added as concepts because it obviates the need for separate InputRange and OutputRange concepts.

    concept Iterator<WeakIterator I> =
        EqualityComparable<I>;

    concept WeakOutputIterator<WeakIterator I, typename T> =
        Writable<I, T>;



    concept OutputIterator<WeakIterator I, typename T> =
        EqualityComparable<I> && Writable<I, T>;

    concept WeakInputIterator<WeakIterator I> =
        Readable<I> && 
        requires(I i) {
            IteratorCategory<I>;
            Derived<IteratorCategory<I>, weak_input_iterator_tag>;
            Readable<decltype(i++)>;
        };

    concept InputIterator<WeakInputIterator I> =
        EqualityComparable<I> &&
        Derived<IteratorCategory<I>, input_iterator_tag>;

    concept ForwardIterator<InputIterator I> =
        Incrementable<I> &&
        Derived<IteratorCategory<I>, forward_iterator_tag>;

    concept BidirectionalIterator<ForwardIterator I> =
        Derived<IteratorCategory<I>, bidirectional_iterator_tag> &&
        requires decrement (I i, I j) {
            // Pre-decrement:
            I& == { ––i };
            axiom { is_valid(––i) => &––i == &i; }
            // Post-decrement:
            I == { i–– };
            axiom {
                is_valid(––i) <=> is_valid(i––);
                is_valid(i––) => (i == j => i–– == j);
                is_valid(i––) => (i == j => (i––, i) == ––j);
            }
        } &&
        axiom increment_decrement (I i, I j) {
            is_valid(++i) => (is_valid(––(++i)) && (i == j => ––(++i) == j));
            is_valid(––i) => (is_valid(++(––i)) && (i == j => ++(––i) == j));
        };

    concept RandomAccessIterator<BidirectionalIterator I> =
        TotallyOrdered<I> &&
        Derived<IteratorCategory<I>, random_access_iterator_tag> &&
        SignedIntegral<DistanceType<I>> &&
        // Difference:
        SizedIteratorRange<I, I> && // see below
        requires advance (I i, I j, DifferenceType<I> n) {
            // Addition:
            I& == { i += n };
            I == { i + n };
            I == { n + i };
            axiom {
                is_valid(advance(i, n) <=> is_valid(i += n);
                is_valid(i += n) => i += n == (advance(i, n), i);
                is_valid(i += n) => &(i += n) == &i;
                is_valid(i += n) => i + n == (i += n);
                // Commutativity of pointer addition
                is_valid(i + n) => i + n == n + i;
                // Associativity of pointer addition
                is_valid(i + (n + n)) => i + (n + n) == (i + n) + n;
                // Peano-like pointer addition:
                i + 0 == i;
                is_valid(i + n) => i + n == ++(i + (n – 1));
                is_valid(++i) => (i == j => ++i != j);
            }
            // Subtraction:
            I& == { i –= n };
            I == { i – n };
            axiom {
                is_valid(i += –n) <=> is_valid(i –= n);
                is_valid(i –= n) => (i –= n) == (i += –n);
                is_valid(i –= n) => &(i –= n) == &i;
                is_valid(i –= n) => (i – n) == (i –= n);
            }
        } &&
        requires subscript (I i, DifferenceType<I> n) {
            ValueType<I> = { i[n] };
            axiom {
                is_valid(i + n) && is_valid(*(i + n)) => i[n] == *(i + n);
            }
        };

##### Iterator Range Concepts

    concept IteratorRange<Iterator I, Regular S> =
        EqualityComparable<I, S>;

    concept SizedIteratorRange<Iterator I, Regular S> =
        IteratorRange<I, S> &&
        requires difference (I i, S j) {
            DifferenceType<I> == { j - i };
            SignedIntegral<DifferenceType>;
            Convertible<DistanceType, DifferenceType>;
            axiom {
                is_valid(distance(i, j)) <=> is_valid(i – j) && is_valid(j – i);
                is_valid(i – j) => (i – j) >= 0 => i – j == distance(i, j);
                is_valid(i – j) => (i – j) < 0 => i – j == –distance(i, j);
            }
        };

##### Range Concepts

    concept Iterable<typename T> =
        requires(T t) {
            IteratorType<T>;
            SentinelType<T>;
            IteratorType<T> == { begin(t) };
            SentinelType<T> == { end(t) };
            IteratorRange<IteratorType, SentinelType>;
        }

    struct range_base
    {};

    // For exposition only:
    concept ContainerLike<Iterable T> =
        !Same<decltype(*begin(declval<T &>())), decltype(*begin(declval<T const &>()))>;

    // For exposition only:
    template<typename T>
    struct is_range_impl_
      : std::integral_constant<
            bool,
            Iterable<T>() && (!ContainerLike<T>() || Derived<T, range_base>())
        >
    {};

    // Specialize this if the default is wrong.
    template<typename T, typename Enable = void>
    struct is_range
      : conditional<
            is_same<T, remove_const_t<remove_reference_t<T>>>::value,
            is_range_impl_<T>,
            is_range<remove_const_t<remove_reference_t<T>>>
        >::type
    {};

    concept Range<Iterable T> =
        Semiregular<T> && True<is_range<T>::value>;

##### Sized Iterable Concepts

The `SizedIterable` concept exists for the same reasons as `SizedIteratorRange`. There are some iterables that, though they are not random-access, know their size in O(1). A prime example is `std::list`. Another example is a counted view (ie., a range specified by an iterator and a count). Some algorithms can select a better implementation when the size of the range is known, even if the iterators don't allow random access.

    // For exposition only:
    concept SizedIterableLike<Iterable T> =
        requires(T t) {
            SizeType<T>;
            Integral<SizeType>;
            Convertible<SizeType, DifferenceType<IteratorType>>
            SizeType<T> == { size(t) };
        }

    // For exposition only:
    template<typename T>
    struct is_sized_iterable_impl_
      : std::integral_constant<
            bool,
            SizedIterableLike<T>()
        >
    {};

    // Specialize this if the default is wrong.
    template<typename T>
    struct is_sized_iterable
      : conditional<
            is_same<T, remove_const_t<remove_reference_t<T>>>::value,
            is_sized_iterable_impl_<T>,
            is_sized_iterable<remove_const_t<remove_reference_t<T>>>
        >::type
    {};

    concept SizedIterable<SizedIterableLike T> =
        True<is_sized_iterable<T>::value> &&
        requires(T t) {
            axiom {
                distance(begin(t), end(t)) == size(t);
            }
        };

VI. Technical Specifications
----------------------------

This section intentionally left blank.

VII. Future Directions
----------------------

- Range extensions to things like regex. Make it work with null-terminated strings, e.g..
- Discuss the pros and cons of tying this work with work on a concept-ified standard library (aka Concepts Lite TS2).
- Discuss the pros and cons of making this (and the concept-ified standard library) *strictly* backwards compatible, versus delivering the new, conceptified and range-ified standard library in a separate, versioned namespace (and what such a solution should look like).
- Discuss how an extension to the Concepts Lite proposal, implicit conversion to concept, bears on the Iterable/Range concepts and the way the algorithms are constrained.

VII. Acknowledgements
---------------------

I would like to give special thanks to Sean Parent for his advice and feedback on early designs of the range library on which this proposal is based, in addition to his work on the Adobe Source Libraries from which this proposal has borrowed liberally.

Also deserving of special thanks is Andrew Sutton. His work on Concepts Lite and on the formulations of the algorithms as specified in N3351 has proven invaluable, and he has generously donated his time and expertise to expound on the ideas there and improve the quality of this proposal.

Chandler Carruth has also helped more than he probably knows. I am indebted to him for his support and perspective.

I would be remiss if I didn't acknowledge the foundational work of all the people whose ideas and sweat have gone into various range libraries and proposals in the past. They are too many to list, but I certainly benefited from the work of Dave Abrahams, Dietmar Kühl, Neil Groves, Thorsten Ottosen, Arno Schoedl, Daniel Walker, and Jeremy Seik.

Of course none of this work would be possible without Alex Stepanov's giant leap forward with the STL, or without Bjarne Stroustrup who gave Alex the instrument he needed to most clearly realize his vision.

VIII. References
----------------

[2]: http://www.boost.org/libs/range "Boost.Range"
[3]: http://stlab.adobe.com/ "Adobe Source Libraries"
[4]: http://dlang.org/phobos/std_range.html "D Phobos std.range"
[5]: https://github.com/Bekenn/range "Position-Based Ranges"
[6]: https://github.com/sean-parent/sean-parent.github.com/wiki/presentations/2013-09-11-cpp-seasoning/cpp-seasoning.pdf "C++ Seasoning, Sean Parent"
[7]: http://www.github.com/ericniebler/range-v3 "Range v3"
[8]: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3351.pdf "A Concept Design for the STL"
[9]: http://www.boost.org/libs/iterator/doc/new-iter-concepts.html "New Iterator Concepts"
[10]: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3782.pdf "Indexed-Based Ranges"
[11]: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2005/n1873.html "The Cursor/Property Map Abstraction"

Appendix 1: Sentinels and Code Generation
-----------------------------------------

In this appendix we explore the effect of the use of sentinels on code generation. I'll show that allowing the type of the end iterator to differ from the begin can have a positive effect on the performance of algorithms. First, I'll note that nothing that can be done with sentinels cannot also be done with appropriately designed end iterators. Here, for instance, is the code for an iterator that can be used to adapt a null-terminated string to the STL. It is implemented with the help of the Boost.Iterators library:

    #include <cassert>
    #include <iostream>
    #include <boost/iterator/iterator_facade.hpp>

    struct c_string_range
    {
    private:
        char const *str_;
    public:
        using const_iterator = struct iterator
          : boost::iterator_facade<
                iterator
              , char const
              , std::forward_iterator_tag
            >
        {
        private:
            friend class boost::iterator_core_access;
            friend struct c_string_range;
            char const * str_;
            iterator(char const * str)
              : str_(str)
            {}
            bool equal(iterator that) const
            {
                return str_
                    ? (that.str_ == str_ ||
                         (!that.str_ && !*str_))
                    : (!that.str_ || !*that.str_);
            }
            void increment()
            {
                assert(str_ && *str_);
                ++str_;
            }
            char const& dereference() const
            {
                assert(str_ && *str_);
                return *str_;
            }
        public:
            iterator()
              : str_(nullptr)
            {}
        };
        c_string_range(char const * str)
          : str_(str)
        {
            assert(str_);
        }
        iterator begin() const
        {
            return iterator{str_};
        }
        iterator end() const
        {
            return iterator{};
        }
        explicit operator bool() const
        {
            return !!*str_;
        }
    };

    int c_strlen(char const *sz)
    {
        int i = 0;
        for(; *sz; ++sz)
            ++i;
        return i;
    }

    int range_strlen(
        c_string_range::iterator begin,
        c_string_range::iterator end)
    {
        int i = 0;
        for(; begin != end; ++begin)
            ++i;
        return i;
    }

The code traverses the sequence of characters without first computing its end. It does it by creating a dummy end iterator such that any time a real iterator is compared to it, it checks to see if the real iterator points to the null terminator. All the comparison logic is in the `c_string_range::iterator::equal` member function.

The functions `c_strlen` and `range_strlen` implement equivalent proceedures for computing the length of a string, the first using raw pointers and a check for the null terminator, the second using `c_string_range`'s STL iterators. The resulting optimized assembly code (clang 3.4 -O3 -DNDEBUG) generated for the two functions highlights the lost optimization opportunities.

<table border="0" cellpadding="0" cellspacing="0" style="border-collapse: collapse" bordercolor="#111111" width="607">
<tr><td><pre><code>c_strlen</code></pre></td><td><pre><code>range_strlen</code></pre></td></tr>
<tr><td valign="top"><pre><code>    pushl   %ebp
    movl    %esp, %ebp
    movl    8(%ebp), %ecx
    xorl    %eax, %eax
    cmpb    $0, (%ecx)
    je      LBB1_3
    xorl    %eax, %eax
    .align  16, 0x90
LBB1_2:
    cmpb    $0, 1(%ecx,%eax)
    leal    1(%eax), %eax
    jne     LBB1_2
LBB1_3:
    popl    %ebp
    ret</code></pre></td><td><pre><code>    pushl   %ebp
    movl    %esp, %ebp
    pushl   %esi
    leal    8(%ebp), %ecx
    movl    12(%ebp), %esi
    xorl    %eax, %eax
    testl   %esi, %esi
    movl    8(%ebp), %edx
    jne     LBB2_4
    jmp     LBB2_1
    .align  16, 0x90
LBB2_8:
    incl    %eax
    incl    %edx
    movl    %edx, (%ecx)
LBB2_4:
    testl   %edx, %edx
    jne     LBB2_5
    cmpb    $0, (%esi)
    jne     LBB2_8
    jmp     LBB2_6
    .align  16, 0x90
LBB2_5:
    cmpl    %edx, %esi
    jne     LBB2_8
    jmp     LBB2_6
    .align  16, 0x90
LBB2_3:
    leal    1(%edx,%eax), %esi
    incl    %eax
    movl    %esi, (%ecx)
LBB2_1:
    movl    %edx, %esi
    addl    %eax, %esi
    je      LBB2_6
    cmpb    $0, (%esi)
    jne     LBB2_3
LBB2_6:
    popl    %esi
    popl    %ebp
    ret</code></pre></td></tr>
</table>

The author has never seen code like `c_string_range` in the wild. Typically, when users want to use an STL algorithm on a C-style string, they call `strlen` to find the end first. (This is what the standard regex algorithms do when passed C-style strings.) That traverses the string an extra time needlessly. Also, such a trick is not possible for input sequences like those traversed by `std::istream_iterator` that consume their input.

Rather than mocking up a dummy end iterator with a computationally expensive equality comparison operation, we can use a sentinel type that encodes end-ness in its type. Below is an example from the [Range-v3 library] [7], which uses a `range_facade` class template to generate iterators and sentinels from a simple range-like interface:

    using namespace ranges;
    struct c_string_iterable
      : range_facade<c_string_iterable>
    {
    private:
        friend range_core_access;
        char const *sz_;
        char const & current() const { return *sz_; }
        void next() { ++sz_; }
        bool done() const { return *sz_ == 0; }
        bool equal(c_string_iterable const &that) const
        { return sz_ == that.sz_; }
    public:
        c_string_iterable() = default;
        c_string_iterable(char const *sz)
            : sz_(sz) {}
    };

    // Iterable-based
    int iterable_strlen(
        range_iterator_t<c_string_iterable> begin,
        range_sentinel_t<c_string_iterable> end)
    {
        int i = 0;
        for(; begin != end; ++begin)
            ++i;
        return i;
    }

The assembly generated for `iterable_strlen` is nearly identical to that for the hand-coded `c_strlen`:

        pushl   %ebp
        movl    %esp, %ebp
        movl    8(%ebp), %ecx
        xorl    %eax, %eax
        cmpb    $0, (%ecx)
        je      LBB1_4
        leal    8(%ebp), %edx
        .align  16, 0x90
    LBB1_2:
        cmpb    $0, 1(%ecx,%eax)
        leal    1(%eax), %eax
        jne     LBB1_2
        addl    %eax, %ecx
        movl    %ecx, (%edx)
    LBB1_4:
        popl    %ebp
        ret

The difference is due to the fact that the sentinel has a different type than the iterator, so that the expression `begin != end` can be optimized into `*begin == 0`. Compare this to the `range_strlen` case shown above. In that case, `begin == end` is comparing two objects of the same type, and since either `begin` or `end` could be a sentinel -- or both, or neither -- the compiler can't elide the extra checks without extra information from the surrounding calling context, which isn't always available; hence, the worse code gen.

In addition to the performance impact, the complexity of implementing a correct `operator==` for an iterator with a dummy sentinel can present problems. Chandler Carruth reports that such comparison operators have been a rich source of bugs for Google.

Appendix 2: Sentinels, Iterators, and the Cross-Type EqualityComparable Concept
-------------------------------------------------------------------------------

This appendix describes the theoretical justification for sentinels from the perspective of the STL concepts as set out in [N3351] [8]. In that paper, the foundational concept EqualityComparable is described in depth, not only its syntactic constraints but also its semantic axioms. It it not enough that the syntax `a == b` compiles. It has to be a meaningful comparison. Here I explain why I believe it is meaningful to compare an iterator with a sentinel of a different type for equality.

In the expression `x == y`, where `x` and `y` have different types, the EqualityComparable concept requires that the types of both `x` and `y` must themselves be EqualityComparable, and there must be a common type to which they can both be converted, and that type must also be EqualityComparable. Think of comparing a `char` with a `short`. It works because both `char` and `short` are EqualityComparable, and because they can both be converted to an `int` which is also EqualityComparable.

Iterators are comparable, and sentinels are trivially comparable (they always compare equal). The tricky part is the common type requirement. Logically, every iterator/sentinel pair has a common type that can be constructed as follows: assume the existence of a new iterator type `I` that is a tagged union that contains *either* an iterator *or* a sentinel. When an iterator is compared to a sentinel, it behaves semantically as if both the iterator and the sentinel were first converted to two objects of type `I` — call them `lhs` and `rhs` — and then compared according to the following truth table:

LHS IS SENTINEL ? | RHS IS SENTINEL ? | LHS == RHS ?
----------------- | ----------------- | ------------
`true`            | `true`            | `true`
`true`            | `false`           | `done(rhs.iter)`
`false`           | `true`            | `done(lhs.iter)`
`false`           | `false`           | `lhs.iter == rhs.iter`

In Appendix 1, there is an implementation of `c_string_range` whose iterator's `operator==` is a procedure for evaluating this truth table. That’s no coincidence; that was a special case of this more general construction.

In summary, for every iterator/sentinel pair, we can construct a common iterator type that implements an equivalent procedure for computing equality. The existence of this common type is what allows iterator/sentinel pairs satisfy the EqualityComparable requirement.

As a final note, the Range v3 library has a general implementation of this common iterator type as a paramterized type, and appropriate specializations of `std::common_type` that allow the constrained algorithms type type-check correctly. It works well in practice, both for the purpose of type-checking the algorithms and for adapting ranges with iterator/sentinel pairs to old code that expects the begin and end of a range to have the same type.

Appendix 3: D Ranges and Algorithmic Complexity
-----------------------------------------------

TODO Discussion of the is_word_boundary example.
